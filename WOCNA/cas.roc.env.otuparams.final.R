################################################################################
################################################################################
# Weighted Gene Correlation Network Analysis


# This method is typically used to analyze correlation for individual genes
# It can also be used to look at OTU abundance data across sampling points. 
# Additionally, the correlative groups that are generated can be analyzed with
# respect to continuous variables, such as the environmental sample data that we
# have obtained from snow.

################################################################################
################################################################################
# Background

# This workflow is from Jeff Bowman's lab webpage with additions and modifications for
# use with our snow community data
# https://www.polarmicrobes.org/weighted-gene-correlation-network-analysis-wgcna-applied-to-microbial-communities/

# WGCNA identifies OTU modules that correlate with environmental/biochemical
# variables and highly abundant OTUs (Brown Lab modification) using hierarchical
# clusters, weighted adjacency functions and topological overlap measures, and a
# dynamic tree cutting method. Each OTU is going to be represented
# by a node in a vast network and the adjacency (a score between 0 and 1)
# between each set of nodes will be calculated. Many networks use
# hard-thresholding (where a connection score [e.g. a Pearson Correlation
# Coefficient] between any two nodes is noted as 1 if it is above a certain
# threshold and noted as 0 if it is below it). This ignores the actual strength
# of the connection so WGCNA constructs a weighted gene (or OTU) co-occurrence
# adjacency matrix in lieu of 'hard' thresholding. for this method to work you
# also have to select a soft thresholding power (sft) to which each
# co-expression similarity is raised in order to make these scores "connection
# strengths". A signed adjacency function: adjacency = 0.5*(1+Pearson
# correlation)^sft was used as soft thresholding preserves the sign of the
# connection (whether nodes are positively or negatively correlated) and this is
# recommended by authors of WGCNA. You pick your soft thresholding value by
# using a scale-free topology. This is based on the idea that the probability
# that a node is connected with k other nodes decays as a power law: p(k)~
# k^(-??) this idea is linked to the growth of networks-new nodes are more
# likely to be attached to already established nodes. In general, scale-free
# networks display a high degree of tolerance against errors (Zhang & Horvath,
# 2005). You then turn your adjacency matrix into a Topological Overlap Measure
# (TOM) to minimize the effects of noise and spurious associations. A
# topological overlap of two nodes also factors in all of their shared neighbors
# (their relative interrelatedness)-so you are basically taking co-occurrence
# between two nodes and placing it in the framework of the entire network by
# factoring in all the other nodes each is connected to. For more information
# regarding adjacency matrices and TOMs see Zhang & Horvath (2005) and
# Langfelder & Horvath (2007 & 2008)."

# Tucker and Brown used a modified version of SABRE (Shannon et al. 2016) to
# quantify the stability and similarity of modules generated by WGCNA. This
# gives the user a measure of boostrap support after OTU moduls are generated.
# They introduced a more automated way of identifying a soft threshold and a a
# way to measure OTU modules vs abundant of OTUs of interest in the WGCNA
# heatmap to understand the influence of highly abundant OTUs on specific
# modules.


################################################################################
################################################################################
# Package setup

# Install required packages
install.packages("WGCNA")
install.packages("entropy")
install.packages("infotheo")
install.packages("fpc")
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("GO.db", version = "3.8")
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("impute", version = "3.8")
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("preprocessCore", version = "3.8")
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("preprocessCore", version = "3.8")

# Load libraries
library(readxl)
library(vegan)
library(preprocessCore)
library(WGCNA)
library(GO.db)
library(entropy)
library(infotheo)
library(impute)
library(cluster)
library(fpc)


################################################################################
################################################################################
# Data setup

# Set working directory
setwd("/Users/BrownLab/Desktop/Students/Avery/projects/snow.bloom.2018/stats.analysis/wgcna/wgcna.final")

# Read in OTU raw abundance values
lineage.cas.raw = read.csv("cas.full.abund.csv", row.names = 1)
lineage.roc.raw = read.csv("roc.full.abund.csv", row.names = 1)

# Read in environmental data
map.cas = read.csv("cas.traits.comm.csv", row.names = 1)
map.roc = read.csv("roc.traits.comm.csv", row.names = 1)
map.roc = map.roc[, -16] # remove A-OTU0002


################################################################################
################################################################################
# Steps

# 1. Turn raw abundance scores into relative abundance scores
# 2. Identify an appropriate soft thresholding value and calculate our adjacency
#    matrix
# 3. Turn adjacency matrix into a topological overlap measure (TOM) and generate
#    cluster modules
# 4. Run SABRE analysis on modules to test similarity and stability
# 5. Quantify co-expression similarity of modules using eigengenes and cluster
#    based on correlation
# 6. Relating modules to external information and IDing important taxa


################################################################################
################################################################################
# 1. Turn raw abundance scores into relative abundance scores 
# (NOTE: We will repeat parts of this step after optimization of the
# soft-threshold power)

# Standardization: raw abundance to relative abundance scores
# Hellinger transform gives more weight to higher abundance OTUs
# Takes the square root of method = "total", where "total": divide by margin
# total with a default margin = 1

lineage.cas.raw = lineage.cas.raw[,which(colSums(lineage.cas.raw) > 10)]
lineage.roc.raw = lineage.roc.raw[,which(colSums(lineage.roc.raw) > 10)]
hell.cas.ra = decostand(lineage.cas.raw, method = "hellinger") 
hell.roc.ra = decostand(lineage.roc.raw, method = "hellinger") 

# Check data for excessive missingness and purge OTUs that have 0 counts in all
# samples for cascades or rockies
hell.cas.ra = hell.cas.ra[, colSums(hell.cas.ra != 0) > 0]
gsg.cas = goodSamplesGenes(hell.cas.ra, verbose = 3)
gsg.cas$allOK
hell.roc.ra = hell.roc.ra[, colSums(hell.roc.ra != 0) > 0]
gsg.roc = goodSamplesGenes(hell.roc.ra, verbose = 3)
gsg.roc$allOK

# Cluster samples and check for outliers
sample.tree.cas = hclust(dist(hell.cas.ra), method = "average")
sizeGrWindow(12,9)
par(cex = 0.6);
par(mar = c(0,4,2,0))
plot(sample.tree.cas, main = "Cascade Sample Clustering", sub="", xlab=""
     , cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)
sample.tree.roc = hclust(dist(hell.roc.ra), method = "average")
sizeGrWindow(12,9)
par(cex = 0.6);
par(mar = c(0,4,2,0))
plot(sample.tree.roc, main = "Rockies Sample Clustering", sub="", xlab=""
     , cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)


################################################################################
################################################################################
# 2.a (data set optimization)

# Note: You have a couple of options for how you create your weighted OTU
# co-expression network.
# Please see this document for information on the other methods
# (https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/Simulated-05-NetworkConstruction.pdf).
# Data can be noisy and the number of samples is often small, it may be useful
# to emphasize strong correlations and to punish weak correlations.
# It is natural to define the adjacency between two genes as a power of the
# absolute value of the correlation coefficient
# Soft-thresholding as opposed to a hard-threshold is what gives "weightedness"
# Be aware that sample order will affect soft-thresholding

# Choose a set of soft-thresholding powers:
powers = c(c(1:10), seq(from = 11, to=30, by=1))

# Network optimization: select the dataset that maximizes the R^2 for scale free
# topology. This program will run through multiple signed networks

# Run for the cascades
# Set an OTU value threshold to test for an optimized dataset
otu.thresh.cas = 1000
max.score.list.cas = c()
d.original.cas = dim(lineage.cas.raw)
sum.incr.cas = 0

while(sum.incr.cas < otu.thresh.cas){
  
  # convert abundances to hellinger values
  hell.cas.ra = decostand(lineage.cas.raw, method = "hellinger")
  
  # generate soft threshold
  sft.cas = pickSoftThreshold(hell.cas.ra, powerVector = powers
                              , verbose = 3, networkType = "unsigned")
  
  # pick the max.r2 from the list
  max.r2.cas = max(-sign(sft.cas$fitIndices[,3])*sft.cas$fitIndices[,2])
  
  # add max R^2 to the list
  max.score.list.cas = c(max.score.list.cas, max.r2.cas)
  
  # remove a single and the lowest abundance OTU from the matrix
  d.cas = dim(lineage.cas.raw)
  rl.cas = -1*d.cas[2]
  lineage.cas.raw = lineage.cas.raw[,rl.cas]
  
  # accumulator variable to see if we have tested all OTUs with 
  # abundance < the abundance threshold
  index.sum.check.cas = c(d.cas[2] - 1)
  sum.incr.cas = sum(lineage.cas.raw[,index.sum.check.cas])
}

sizeGrWindow(12,9)
par(cex = 0.6);
par(mar = c(3,4,2,4))
plot(max.score.list.cas)
abline(h=0.8, v=402,col="red")

index.max.cas = which.max(max.score.list.cas)

################################################################################
# Run for the rockies

# Set an OTU index threshold to test for an optimized dataset
otu.thresh.roc = 1000
max.score.list.roc = c()
d.original.roc = dim(lineage.roc.raw)
sum.incr.roc = 0

while(sum.incr.roc < otu.thresh.roc){
  
  # convert abundances to hellinger values
  hell.roc.ra = decostand(lineage.roc.raw, method = "hellinger")
  
  # generate soft threshold
  sft.roc = pickSoftThreshold(hell.roc.ra, powerVector = powers
                              , verbose = 3, networkType = "unsigned")
  
  # pick the max.r^2 from the list
  max.r2.roc = max(-sign(sft.roc$fitIndices[,3])*sft.roc$fitIndices[,2])
  
  # add max.r^2 to the list
  max.score.list.roc = c(max.score.list.roc, max.r2.roc)
  
  # remove a single and the lowest abundance OTU from the matrix
  d.roc = dim(lineage.roc.raw)
  rl.roc = -1*d.roc[2]
  lineage.roc.raw = lineage.roc.raw[,rl.roc]
  
  # accumulator variable to see if we have tested all OTUs with 
  # abundance < the abundance threshold
  index.sum.check.roc = c(d.roc[2] - 1)
  sum.incr.roc = sum(lineage.roc.raw[,index.sum.check.roc])
}

sizeGrWindow(12,9)
par(cex = 0.6);
par(mar = c(3,4,2,4))
plot(max.score.list.roc)
abline(h=0.8,v=425,col="red")
index.max.roc = which.max(max.score.list.roc)

################################################################################
# OTU threshold for the Cascades and Rockies to use as cutoff for final matrix
# Selected the OTU threshold with best scale-free topology fit index (R^2)

# Reload abundance data matrix and re-remove OTUs with abundance < 10
lineage.cas.raw = read.csv("cas.full.abund.csv", row.names = 1)
lineage.cas.raw <- lineage.cas.raw[,which(colSums(lineage.cas.raw) > 10)]
lineage.roc.raw = read.csv("roc.full.abund.csv", row.names = 1)
lineage.roc.raw = lineage.roc.raw[,which(colSums(lineage.roc.raw) > 10)]

# Remove OTUs up to threshold to trim our dataset for optimal scale-free
# topology
index.cull.to.cas = length(lineage.cas.raw) - 401 # or index.max.cas
index.cull.to.roc = length(lineage.roc.raw) - 423 # or index.max.roc
lineage.cas.opt = lineage.cas.raw[,0:index.cull.to.cas]
lineage.roc.opt = lineage.roc.raw[,0:index.cull.to.roc]

# !! Check average connectivity below and ensure it is > 1.0, if lower than 1.0
# select the next highest R^2 fit !!


################################################################################
################################################################################
# 2.b (select soft-power)

# Rerun hellenger transform
# Convert abundances to hellinger values
hell.cas.ra = decostand(lineage.cas.opt, method = "hellinger")
hell.roc.ra = decostand(lineage.roc.opt, method = "hellinger")

# Network topology analysis function:
# Use a signed network because it preserves the sign of the connection 
# (whether nodes are positively or negatively correlated)
sft.cas = pickSoftThreshold(hell.cas.ra, powerVector = powers
                            , verbose = 3, networkType = "unsigned")
sft.roc = pickSoftThreshold(hell.roc.ra, powerVector = powers
                            , verbose = 3, networkType = "unsigned")

# plot the results
# scale-free topology fit index (R^2) as a function of the soft-thresholding
# power:
sizeGrWindow(9, 5)
par(mfrow = c(1,1))
cex1 = 0.9
plot(sft.cas$fitIndices[,1]
     , -sign(sft.cas$fitIndices[,3])*sft.cas$fitIndices[,2]
     , xlab="Soft Threshold (power)"
     , ylab="Scale Free Topology Model Fit,signed R^2",type="n"
     , main = paste("Scale independence (Cascades)"))
text(sft.cas$fitIndices[,1]
     , -sign(sft.cas$fitIndices[,3])*sft.cas$fitIndices[,2]
     , labels=powers,cex=cex1,col="red")
abline(h=0.8,col="red")

sizeGrWindow(9, 5)
par(mfrow = c(1,1))
cex1 = 0.9
plot(sft.roc$fitIndices[,1]
     , -sign(sft.roc$fitIndices[,3])*sft.roc$fitIndices[,2]
     , xlab="Soft Threshold (power)"
     , ylab="Scale Free Topology Model Fit,signed R^2", type="n"
     , main = paste("Scale independence (Rockies)"))
text(sft.roc$fitIndices[,1]
     , -sign(sft.roc$fitIndices[,3])*sft.roc$fitIndices[,2]
     , labels=powers,cex=cex1,col="red")
abline(h=0.8,col="red")

# Mean connectivity as a function of the soft-thresholding power:
plot(sft.cas$fitIndices[,1], sft.cas$fitIndices[,5]
     , xlab="Soft Threshold (power)"
     , ylab="Mean Connectivity", type="n"
     , main = paste("Mean connectivity (Cascades)"))
text(sft.cas$fitIndices[,1]
     , sft.cas$fitIndices[,5], labels=powers, cex=cex1,col="red")
abline(h=1, col="red")

plot(sft.roc$fitIndices[,1], sft.roc$fitIndices[,5]
     , xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n"
     , main = paste("Mean connectivity (Rockies)"))
text(sft.roc$fitIndices[,1], sft.roc$fitIndices[,5]
     , labels=powers, cex=cex1,col="red")
abline(h=1, col="red")

# Picked a soft thresholding value > 0.8
softPower.cas = 7
adjacency.cas = adjacency(hell.cas.ra
                          , power = softPower.cas, type = "unsigned")
softPower.roc = 9
adjacency.roc = adjacency(hell.roc.ra
                          , power = softPower.roc, type = "unsigned")

# Print mean connectivity and R^2 for reporting
cas.r.sq = -sign(sft.cas$fitIndices[softPower.cas,3])*
  sft.cas$fitIndices[softPower.cas,2]
cas.mean.conn = sft.cas$fitIndices[softPower.cas,5]
cas.r.sq
cas.mean.conn

roc.r.sq = -sign(sft.roc$fitIndices[softPower.roc,3])*
  sft.roc$fitIndices[softPower.roc,2]
roc.mean.conn = sft.roc$fitIndices[softPower.roc,5]
roc.r.sq
roc.mean.conn


################################################################################
################################################################################
# 1. (Repeated for image generation after optimization of the soft-threshold)

# Cluster samples and check for outliers
sample.tree.cas = hclust(dist(hell.cas.ra), method = "average")
sizeGrWindow(15,9)
par(cex = 0.6);
par(mar = c(2,5,3,2))
plot(sample.tree.cas, main = "Cascade Sample Clustering", sub=""
     , xlab="", cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)
sample.tree.roc = hclust(dist(hell.roc.ra), method = "average")
sizeGrWindow(15,9)
par(cex = 0.6);
par(mar = c(3,6,4,4))
plot(sample.tree.roc, main = "Rockies Sample Clustering", sub=""
     , xlab="", cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)

#add colors to our tree
tree.colors.cas = numbers2colors(map.cas[4:26], signed = FALSE)
row.names(tree.colors.cas) = row.names(map.cas)
tree.colors.roc = numbers2colors(map.roc[4:25], signed = FALSE)
row.names(tree.colors.roc) = row.names(map.roc)

# reordering of heatmap
plotOrderedColors(row.names(tree.colors.cas), tree.colors.cas
                  , rowLabels = names(map.cas[1:26]))
plotOrderedColors(row.names(tree.colors.roc), tree.colors.roc
                  , rowLabels = names(map.roc[1:25]))

# plot the sample dendrogram and the colors underneath
plotDendroAndColors(sample.tree.cas, tree.colors.cas 
                    , groupLabels = names(map.cas[4:26])
                    , main = "Cascade Sample Dendrogram and Trait Heatmap (Community)")
plotDendroAndColors(sample.tree.roc, tree.colors.roc 
                    , groupLabels = names(map.roc[4:25])
                    , main = "Rockies Sample Dendrogram and Trait Heatmap (Community)")

################################################################################
################################################################################
# 3. Turn adjacency matrix into a topological overlap measure (TOM) and generate
# cluster modules

# Transform the adjacency matrix into a Topological Overlap Matrix (TOM) and
# calculate corresponding dissimilarity
# The TOM we shows the topological similarity of nodes, factoring in the
# connection strength two nodes share with other “third party” nodes
# Minimizes effects of noise and spurious associations
TOM.cas = TOMsimilarity(adjacency.cas, TOMType = "unsigned")
dissTOM.cas = 1-TOM.cas
TOM.roc = TOMsimilarity(adjacency.roc, TOMType = "unsigned")
dissTOM.roc = 1-TOM.roc

# Create a dendogram using a hierarchical clustering tree and then call the
# hierarchical clustering function:

# Ward's minimum variance is the agglomerative approach used here, which I chose
# is it generated the most interpretable hierarchy
TaxaTree.cas = hclust(as.dist(dissTOM.cas), method = "ward.D2")
TaxaTree.roc = hclust(as.dist(dissTOM.roc), method = "ward.D2")

# Plot the dendrogram:
sizeGrWindow(1,1)
par(cex = 1)
par(mar = c(4,4,6,4))
plot(TaxaTree.cas, xlab="", sub=""
     , main = "Community Taxa Clustering\n of TOM-based Dissimilarity \n(Cascades)"
     , labels = FALSE, hang = 0.05)
abline(h=2.25,col="red")
plot(TaxaTree.roc, xlab="", sub=""
     , main = "Community Taxa Clustering\n of TOM-based Dissimilarity \n(Rockies)"
     , labels = FALSE, hang = 0.05)
abline(h=1.75,col="red")

# (Optional) hierarchical clustering validation using silhouettes, the higher
# the average silhouette the better the classification scheme
K.cas = seq(2,100)
si.hc.cas = c()
for(k in K.cas) {
  si = silhouette(cutree(TaxaTree.cas, k=k), dissTOM.cas)
  si.hc.cas = c(si.hc.cas, summary(si)$avg.width)
}
plot(K.cas, si.hc.cas, xlim=c(0,max(K.cas)), pch=16, col="red", cex=1.5
     , main="Hierarchical Clustering\n (Cascades)"
     , ylab="Average silhouette value")
si.hc19.cas = silhouette(cutree(TaxaTree.cas, k=19), dissTOM.cas)
plot(si.hc19.cas)

K.roc = seq(2,100)
si.hc.roc = c()
for(k in K.roc) {
  si = silhouette(cutree(TaxaTree.roc, k=k), dissTOM.roc)
  si.hc.roc = c(si.hc.roc, summary(si)$avg.width)
}
plot(K.roc, si.hc.roc, xlim=c(0,max(K.roc)), pch=16, col="red", cex=1.5
     , main="Hierarchical Clustering\n (Rockies)"
     , ylab="Average silhouette value")
si.hc19.roc = silhouette(cutree(TaxaTree.roc, k=22), dissTOM.roc)
plot(si.hc19.roc)

# Select our minimum module size
minModuleSize.cas = 14
minModuleSize.roc = 6

# Module identification using dynamic tree cut (there a couple of different ways
# to figure out your modules and so you should explore what works best for you
# in the tutorials by the authors):
dynamicMods.cas = cutreeDynamic(dendro = TaxaTree.cas, distM = dissTOM.cas
                                , cutHeight = 2.25
                                , deepSplit = 2, pamRespectsDendro = FALSE
                                , minClusterSize = minModuleSize.cas)
dynamicMods.roc = cutreeDynamic(dendro = TaxaTree.roc, distM = dissTOM.roc
                                , cutHeight = 1.75
                                , deepSplit = 2, pamRespectsDendro = FALSE
                                , minClusterSize = minModuleSize.roc)

# Check the number of modules created and define for later use (see section 6)
table(dynamicMods.cas)
table(dynamicMods.roc)

num.mods.cas = range(dynamicMods.cas)[2]
num.mods.roc = range(dynamicMods.roc)[2]

# Convert numeric labels into colors
dynamicColors.cas = labels2colors(dynamicMods.cas)
table(dynamicColors.cas)
dynamicColors.roc = labels2colors(dynamicMods.roc)
table(dynamicColors.roc)

# Plot the dendrogram with module colors underneath
plotDendroAndColors(TaxaTree.cas, dynamicColors.cas, "Tree Cut Modules"
                    , dendroLabels = FALSE, hang = 0.03
                    , addGuide = TRUE, guideHang = 0.05
                    , main = "Community OTU Dendrogram and Module Colors\n (Cascades)")

plotDendroAndColors(TaxaTree.roc, dynamicColors.roc, "Tree Cut Modules"
                    , dendroLabels = FALSE, hang = 0.03
                    , addGuide = TRUE, guideHang = 0.05
                    , main = "Community OTU Dendrogram and Module Colors\n (Rockies)")


################################################################################
################################################################################
# 4. Run SABRE analysis on modules to test similarity and stability 
# (see R workflow "roc.cas.similarity.R")

# For more information see "SABRE: a method for assessing the stability of gene
# modules in complex tissues and subject populations" by Shannon et al. 2016
# SABRE: similarity across boostrap re-sampling
# This analysis will give a similarity score for individual reference modules.
# It also generates boostrap support for an h-index that gives a notion of
# module stability. Higher sample numbers result in higher module similarity and
# stability

# extract module clusters

# Load modified CBI compatible with package fpcs's clusterboot function
# This modified CBI was introduced as we used a dynamic, rather than static,
# tree cut method
dynamic.hclustCBI <- function(dmatrix,k,cut="number",method,noisecut=0,...){
  n <- nrow(as.matrix(dmatrix))
  c1 <- hclust(as.dist(dmatrix),method=method)
  noise <- FALSE
  if (cut=="number")
    partition <- cutreeDynamic(dendro = c1, distM = dmatrix, cutHeight = cut,
                               deepSplit = 1, pamRespectsDendro = FALSE,
                               minClusterSize = minModuleSize)
  else
    partition <- cutreeDynamic(dendro = c1, distM = dmatrix, cutHeight = "tree",
                               deepSplit = 1, pamRespectsDendro = FALSE,
                               minClusterSize = minModuleSize)
  nc <- max(partition)
  clsizes <- numeric(0)
  for (i in 1:nc) clsizes[i] <- sum(partition==i)
  ncn <- sum(clsizes>noisecut)
  if (ncn<nc){
    noise <- TRUE
    newcln <- (1:nc)[clsizes>noisecut]
    nc <- ncn+1
    newpart <- rep(nc,n)
    for (i in 1:ncn)
      newpart[partition==newcln[i]] <- i
    partition <- newpart
  }
  cl <- list()
  #  print(nc)
  #  print(sc1)
  for (i in 1:nc)
    cl[[i]] <- partition==i
  out <- list(result=c1,noise=noise,nc=nc,nccl=ncn,
              clusterlist=cl,partition=partition,
              clustermethod="dynamic.hclust")
  out
}

# run the cluster boot
boot.cas <- clusterboot(data = as.dist(TOM.cas), distance = TRUE, B = 100, bootmethod = "boot", 
                               recover = 0.6, bscompare = TRUE,
                               clustermethod = dynamic.hclustCBI, dmatrix = TOM.cas, 
                               k = num.mods.cas, cut="number", method = "ward.D2", noisecut = 0, minModuleSize.cas)
boot.cas
boot.cas$result

boot.roc <- clusterboot(data = as.dist(TOM.roc), distance = TRUE, B = 100, bootmethod = "boot", 
                        recover = 0.6, bscompare = TRUE,
                        clustermethod = dynamic.hclustCBI, dmatrix = TOM.roc, 
                        k = num.mods.roc, cut="number", method = "ward.D2", noisecut = 0, minModuleSize.cas)
boot.roc

################################################################################
################################################################################
# 5. Quantify co-expression similarity of modules using eigengenes and cluster
# based on correlation

# Quantify co-expression similarity of the entire modules using eigengenes
# Cluster eigengenes based on their correlation

# An eigengene is the 1st principal component of a module expression matrix 
# An eigengene represents a defined average OTU community (based on our previous
# ree generation and cutting)

# Calculate eigengenes
MEList.cas = moduleEigengenes(hell.cas.ra, colors = dynamicColors.cas)
MEs.cas = MEList.cas$eigengenes
MEList.roc = moduleEigengenes(hell.roc.ra, colors = dynamicColors.roc)
MEs.roc = MEList.roc$eigengenes

# Calculate dissimilarity of module eigengenes
MEDiss.cas = 1-cor(MEs.cas)
MEDiss.roc = 1-cor(MEs.roc)

# Cluster module eigengenes
METree.cas = hclust(as.dist(MEDiss.cas), method = "ward.D2")
METree.roc = hclust(as.dist(MEDiss.roc), method = "ward.D2");

# Chose a height cut of 0.25
MEDissThres.cas = 0.25
MEDissThres.roc = 0.25

# Plot the result and cut line into the dendrogram
sizeGrWindow(9, 5)
par(mfrow = c(1,1))
cex1 = 0.9
plot(METree.cas, main = "Clustering of Community Module Eigengenes
     \n (Cascades)"
     , xlab = "", sub = "")
abline(h = MEDissThres.cas, col = "red")
plot(METree.roc, main = "Clustering of Community Module Eigengenes
     \n (Rockies)"
     , xlab = "", sub = "")
abline(h = MEDissThres.roc, col = "red")

# Call an automatic merging function
merge.cas = mergeCloseModules(hell.cas.ra, dynamicColors.cas
                              , cutHeight = MEDissThres.cas, verbose = 3)
merge.roc = mergeCloseModules(hell.roc.ra, dynamicColors.roc
                              , cutHeight = MEDissThres.roc, verbose = 3)

# The merged module colors
mergedColors.cas = merge.cas$colors
mergedColors.roc = merge.roc$colors

# Eigengenes of the new merged modules:
mergedMEs.cas = merge.cas$newMEs
mergedMEs.roc = merge.roc$newMEs

# Check if different modules were correctly merged to associated eigengenes
plotDendroAndColors(TaxaTree.cas, cbind(dynamicColors.cas, mergedColors.cas)
                    , c("Dynamic Tree Cut", "Merged dynamic")
                    , dendroLabels = FALSE, hang = 0.03
                    , addGuide = TRUE, guideHang = 0.05)

plotDendroAndColors(TaxaTree.roc, cbind(dynamicColors.roc, mergedColors.roc)
                    , c("Dynamic Tree Cut", "Merged dynamic")
                    , dendroLabels = FALSE, hang = 0.03
                    , addGuide = TRUE, guideHang = 0.05)

# Rename to moduleColors
moduleColors.cas = mergedColors.cas
moduleColors.roc = mergedColors.roc

# Construct numerical labels corresponding to the colors
colorOrder.cas = c("grey", standardColors(50))
moduleLabels.cas = match(moduleColors.cas, colorOrder.cas)-1
MEs.cas = mergedMEs.cas

colorOrder.roc = c("grey", standardColors(50))
moduleLabels.roc = match(moduleColors.roc, colorOrder.roc)-1
MEs.roc = mergedMEs.roc

################################################################################
# Extra Visualization--can do after modules are assigned
cmd1.cas = cmdscale(as.dist(dissTOM.cas), 2)
sizeGrWindow(1,1)
par(mfrow = c(1, 1)) 
par(mar = c(6,5,5,3))
plot(cmd1.cas, col = as.character(dynamicColors.cas)
     , main = "MDS plot (Cascades)"
     , xlab = "Scaling Dimension 1"
     , ylab = "Scaling Dimension 2"
     , cex.axis = 1.5 , cex.lab = 1.5, cex.main = 1.5) 

cmd1.roc = cmdscale(as.dist(dissTOM.roc), 2)
par(mfrow = c(1, 1)) 
plot(cmd1.roc, col = as.character(dynamicColors.roc)
     , main = "MDS plot (Rockies)"
     , xlab = "Scaling Dimension 1"
     , ylab = "Scaling Dimension 2"
     , cex.axis = 1.5 , cex.lab = 1.5, cex.main = 1.5) 


################################################################################
################################################################################
# 6.a Relating modules to external information and IDing important taxa

# Relating modules to external information and IDing important taxa
# Identify modules that are significantly associated with the measured
# environmental traits:

# Correlate eigengenes with environmental traits and look for significant
# associations:
# first, define numbers of OTUs and samples
nTaxa.cas = ncol(hell.cas.ra)
nSamples.cas = nrow(hell.cas.ra)
nTaxa.roc = ncol(hell.roc.ra)
nSamples.roc = nrow(hell.roc.ra)

# Recalculate module eigengenes with color labels
MEs0.cas = moduleEigengenes(hell.cas.ra, moduleColors.cas)$eigengenes
MEs.cas = orderMEs(MEs0.cas)
MEs0.roc = moduleEigengenes(hell.roc.ra, moduleColors.roc)$eigengenes
MEs.roc = orderMEs(MEs0.roc)

moduleTraitCor.cas = cor(MEs.cas, map.cas[4:14]
            , use = "p", method = c("kendall"))
moduleTraitPvalue.cas = corPvalueStudent(moduleTraitCor.cas, nSamples.cas)
moduleTraitCor.roc = cor(MEs.roc, map.roc[4:14]
            , use = "p", method = c("kendall"))
moduleTraitPvalue.roc = corPvalueStudent(moduleTraitCor.roc, nSamples.roc)

# Display correlations and their p-values
textMatrix.cas = paste(signif(moduleTraitCor.cas, 2), "\n("
            , signif(moduleTraitPvalue.cas, 1), ")", sep = "")
dim(textMatrix.cas) = dim(moduleTraitCor.cas)
par(mar = c(20, 20, 20, 20)+0.1, cex.axis = 100000)
sizeGrWindow(100,100)
textMatrix.roc = paste(signif(moduleTraitCor.roc, 2), "\n("
            , signif(moduleTraitPvalue.roc, 1), ")", sep = "")
dim(textMatrix.roc) = dim(moduleTraitCor.roc)
par(mar = c(20, 20, 20, 20)+0.1, cex.axis = 100000)
sizeGrWindow(100,100)

# Display the correlation values within a heatmap plot for environmental
# parameters
sizeGrWindow(9, 5)
par(mfrow = c(1,1))
par(mar = c(5, 7, 4, 1.5))
cex1 = 0.9

labeledHeatmap(Matrix = moduleTraitCor.cas
               , xLabels = names(map.cas[4:14])
               , yLabels = names(MEs.cas)
               , ySymbols = names(MEs.cas)
               , colorLabels = FALSE
               , colors = blueWhiteRed(50)
               , textMatrix = textMatrix.cas
               , setStdMargins = FALSE
               , cex.text = 0.5
               , zlim = c(-1,1)
               , main = paste("Community Module-Environmental Relationships\n(Cascades)"))
labeledHeatmap(Matrix = moduleTraitCor.roc
               , xLabels = names(map.roc[4:14])
               , yLabels = names(MEs.roc)
               , ySymbols = names(MEs.roc)
               , colorLabels = FALSE
               , colors = blueWhiteRed(50)
               , textMatrix = textMatrix.roc
               , setStdMargins = FALSE
               , cex.text = 0.5
               , zlim = c(-1,1)
               , main = paste("Community Module-Environmental Relationships\n(Rockies)"))

# Each row corresponds to a module eigengene, column to an Environmental trait
# Each cell contains the corresponding Pearson correlation coefficient (top
# number) and p-vlaue (in parentheses)
# Table is color-coded by correlation according to the color legend


################################################################################
################################################################################
# 6.b
# Calculate module eigenvalues for module vs OTU comparisons

# Generate eigenvalues for interested OTUs with the OTU of interest removed from
# the dataset, which will artifically skew our results

# Select OTU columns we are interested in correlating our modules to and place
# column number in this vector
cas.otu = c(1,2,25,26,27,28,29,69,70,71,72,73)
cas.otu.eigen = matrix()
for(i in cas.otu) {
  eigen.cas = moduleEigengenes(hell.cas.ra[,-i]
                               , moduleColors.cas[-i])$eigengenes
  for(n in 1:num.mods.cas) {
    colnames(eigen.cas)[n] <- paste(colnames(hell.cas.ra[i])
                                    , colnames(eigen.cas[n]))
  }
  cas.otu.eigen = cbind(cas.otu.eigen, eigen.cas)
}
cas.otu.eigen = cas.otu.eigen[,-1]

# Select OTU columns we are interested in correlating our modules to and place
# column numbers the vector below
roc.otu = c(1,16,17,18,19,20,58,59,60,61,62)
roc.otu.eigen = matrix()
for(i in roc.otu) {
  eigen.roc = moduleEigengenes(hell.roc.ra[,-i]
                               , moduleColors.roc[-i])$eigengenes
  for(n in 1:num.mods.roc) {
    colnames(eigen.roc)[n] <- paste(colnames(hell.roc.ra[i])
                                    , colnames(eigen.roc[n]))
  }
  roc.otu.eigen = cbind(roc.otu.eigen, eigen.roc)
}
roc.otu.eigen = roc.otu.eigen[,-1]


################################################################################
# Generate module-OTU correlation matrices for all modules

# 15:26 is the range where Cascade OTU parameters lie in our variable map
# Change accordingly to the column range in your variable map you would like
# to depict in the final heat matrix
s = 1
f = num.mods.cas # number of modules
cas.mat = matrix(nrow = f, ncol = s)
for(i in 15:26) {
  module.cor.cas = cor(cas.otu.eigen[,s:f]
                       , map.cas[i], use = "p", method = c("kendall"))
  cas.mat = cbind(cas.mat, module.cor.cas)
  s = s + num.mods.cas
  f = f + num.mods.cas
}
module.otu.cor.cas = cas.mat[,-1]
rownames(module.otu.cor.cas)[1:num.mods.cas] <- colnames(MEs0.cas)
module.otu.pvalue.cas = corPvalueStudent(module.otu.cor.cas
                                         , nSamples.cas)

s = 1 # module start
f = num.mods.roc # module end
roc.mat = matrix(nrow = f, ncol = s)
for(i in 15:25) {
  module.cor.roc = cor(roc.otu.eigen[,s:f]
                       , map.roc[i], use = "p", method = c("kendall"))
  roc.mat = cbind(roc.mat, module.cor.roc)
  s = s + num.mods.roc  
  f = f + num.mods.roc
}
module.otu.cor.roc = roc.mat[,-1]
rownames(module.otu.cor.roc)[1:num.mods.roc] <- colnames(MEs0.roc)
module.otu.pvalue.roc = corPvalueStudent(module.otu.cor.roc
                                         , nSamples.roc)

# Display correlations and their p-values then generate heatmaps for module-OTU
# correlations
sizeGrWindow(9, 5)
par(mfrow = c(1,1))
par(mar = c(5, 4, 4, 1.5))
cex1 = 0.9

text.matrix.cas = paste(signif(module.otu.cor.cas, 2), "\n("
                        , signif(module.otu.pvalue.cas, 1), ")", sep = "")

labeledHeatmap(Matrix = module.otu.cor.cas
               , xLabels = names(map.cas[15:26])
               , yLabels = rownames(module.otu.cor.cas)
               , ySymbols = names(module.otu.cor.cas)
               , colorLabels = FALSE
               , colors = blueWhiteRed(50)
               , textMatrix = text.matrix.cas
               , setStdMargins = FALSE
               , cex.text = 0.5
               , zlim = c(-1,1)
               , main = paste("Community Module-OTU Relationships\n(Cascades)"))

text.matrix.roc = paste(signif(module.otu.cor.roc, 2), "\n("
                        , signif(module.otu.pvalue.roc, 1), ")", sep = "")

labeledHeatmap(Matrix = module.otu.cor.roc
               , xLabels = names(map.roc[15:25])
               , yLabels = rownames(module.otu.cor.roc)
               , ySymbols = names(module.otu.cor.roc)
               , colorLabels = FALSE
               , colors = blueWhiteRed(50)
               , textMatrix = text.matrix.roc
               , setStdMargins = FALSE
               , cex.text = 0.5
               , zlim = c(-1,1)
               , main = paste("Community Module-OTU Relationships\n(Rockies)"))


################################################################################
################################################################################
#6.c
# Quantify associations of individual taxa with our trait(s) of interest
# The output here gives us information on the underlying OTU module relationship 
# to any variables we would like to look at in depth

# This will be run as a for loop to generate as we have 23 parameter to OTU 
# comparisons

################################################################################
# In depth module exploration of Cascade OTUs

# Set our parameter map (Cascades), if more than one
map = map.cas
MEs = MEs.cas
data = lineage.cas.opt # use the optimized data set
nTaxa = ncol(lineage.cas.opt)
nSamples = nrow(lineage.cas.opt)
moduleColors = moduleColors.cas
region.name = "(Cascade)"

# load taxonomy names and remove OTUs
lineage.taxonomy = read.csv("community.lineage.taxonomy.csv")
probes = names(data)
probes2annot = match(probes, lineage.taxonomy$OTU)

# The following is the number or probes without annotation: should return 0
sum(is.na(probes2annot))

# Set the range of variables within map that you want outputs for
for (i in 4:26) {
  trait.of.interest = as.data.frame(map[i])
  names(trait.of.interest) = names(map[i])
  toi.name = names(trait.of.interest)
  
  # names (colors) of the modules
  modNames = substring(names(MEs), 3)
  TaxaModuleMembership = as.data.frame(cor(data, MEs, use = "p"))
  MMPvalue = as.data.frame(corPvalueStudent(as.matrix(TaxaModuleMembership)
                                            , nSamples))
  names(TaxaModuleMembership) = paste("MM", modNames, sep="")
  names(MMPvalue) = paste("p.MM", modNames, sep="")
  TaxaTraitSignificance = as.data.frame(cor(data
                                            , trait.of.interest, use = "p"))
  GSPvalue = as.data.frame(corPvalueStudent(as.matrix(TaxaTraitSignificance)
                                            , nSamples))
  names(TaxaTraitSignificance) = paste("GS.", names(trait.of.interest), sep="")
  names(GSPvalue) = paste("p.GS.", names(trait.of.interest), sep="")
  
  # print and save module correlations
  for (j in 1:length(modNames)) {
    module = modNames[j]
    column = match(module, modNames)
    moduleTaxa = (moduleColors == module)
    merge.name.pdf = paste(toi.name, ".", module
                           , ".community.scatterplot.cas.pdf", sep = '')
    pdf(file = merge.name.pdf)
    verboseScatterplot(abs(TaxaModuleMembership[moduleTaxa, column])
                       , abs(TaxaTraitSignificance[moduleTaxa, 1])
                       , xlab = paste("Module Membership in", module, "Module")
                       , ylab = paste("Community Taxa Significance for"
                                      , names(trait.of.interest))
                       , main = paste("Module Membership vs. Taxa Significance\n")
                       , cex.main = 1.2
                       , cex.lab = 1.2
                       , cex.axis = 1.2
                       , col = module)
    dev.off()
    
  }
  # Merge statistical info from previous section (modules with high assocation
  # with trait of interest) with taxa annotation and write a file
  # that summarizes these results
  
  # Create the starting data frame
  TaxaInfo0 = data.frame(Taxon = probes
                         , TaxaSymbol = lineage.taxonomy$genus[probes2annot]
                         , LinkID = lineage.taxonomy$OTU[probes2annot]
                         , moduleColor = moduleColors
                         , TaxaTraitSignificance
                         , GSPvalue)
  
  # Order modules by their significance for our environmental trait of interest
  modOrder = order(-abs(cor(MEs, trait.of.interest, use = "p")))
  
  # Add module membership information in the chosen order
  for (mod in 1:ncol(TaxaModuleMembership)) {
    oldNames = names(TaxaInfo0)
    TaxaInfo0 = data.frame(TaxaInfo0, TaxaModuleMembership[, modOrder[mod]],
                           MMPvalue[, modOrder[mod]]);
    names(TaxaInfo0) = c(oldNames, paste("MM.", modNames[modOrder[mod]], sep=""),
                         paste("p.MM.", modNames[modOrder[mod]], sep=""))
  }
  
  # Order the OTUs in the geneInfo variable first by module color, then by
  # geneTraitSignificance
  TaxaOrder = order(TaxaInfo0[4], -abs(TaxaInfo0[5]))
  TaxaInfo = TaxaInfo0[TaxaOrder, ]
  
  # Write file
  
  merge.name.csv = paste(toi.name,".community.TaxaInfo.cas.csv", sep = '')
  write.csv(TaxaInfo, file = merge.name.csv)
}


################################################################################
# Set our parameter map (Rockies), if more than one
map = map.roc
MEs = MEs.roc
data = lineage.roc.opt # use the optimized data set
nTaxa = ncol(lineage.roc.opt)
nSamples = nrow(lineage.roc.opt)
moduleColors = moduleColors.roc
region.name = "(Rockies)"

# load taxonomy names and remove OTUs
lineage.taxonomy = read.csv("community.lineage.taxonomy.csv")
probes = names(data)
probes2annot = match(probes, lineage.taxonomy$OTU)

# The following is the number or probes without annotation: should return 0
sum(is.na(probes2annot))

for (i in 4:25) {
  trait.of.interest = as.data.frame(map[i])
  names(trait.of.interest) = names(map[i])
  toi.name = names(trait.of.interest)
  modNames = substring(names(MEs), 3)
  TaxaModuleMembership = as.data.frame(cor(data, MEs, use = "p"))
  MMPvalue = as.data.frame(corPvalueStudent(as.matrix(TaxaModuleMembership)
                                            , nSamples))
  names(TaxaModuleMembership) = paste("MM", modNames, sep="")
  names(MMPvalue) = paste("p.MM", modNames, sep="")
  TaxaTraitSignificance = as.data.frame(cor(data, trait.of.interest, use = "p"))
  GSPvalue = as.data.frame(corPvalueStudent(as.matrix(TaxaTraitSignificance)
                                            , nSamples))
  names(TaxaTraitSignificance) = paste("GS.", names(trait.of.interest), sep="")
  names(GSPvalue) = paste("p.GS.", names(trait.of.interest), sep="")
  for (j in 1:length(modNames)) {
    module = modNames[j]
    column = match(module, modNames)
    moduleTaxa = (moduleColors == module)
    merge.name.pdf = paste(toi.name, ".", module
                           , ".community.scatterplot.roc.pdf", sep = '')
    pdf(file = merge.name.pdf)
    verboseScatterplot(abs(TaxaModuleMembership[moduleTaxa, column])
                       , abs(TaxaTraitSignificance[moduleTaxa, 1])
                       , xlab = paste("Module Membership in", module, "Module")
                       , ylab = paste("Community Taxa Significance for"
                                      , names(trait.of.interest))
                       , main = paste("Module Membership vs. Taxa Significance\n")
                       , cex.main = 1.2
                       , cex.lab = 1.2
                       , cex.axis = 1.2
                       , col = module)
    dev.off()
    
  }
  TaxaInfo0 = data.frame(Taxon = probes
                         , TaxaSymbol = lineage.taxonomy$genus[probes2annot]
                         , LinkID = lineage.taxonomy$OTU[probes2annot]
                         , moduleColor = moduleColors
                         , TaxaTraitSignificance
                         , GSPvalue)
  modOrder = order(-abs(cor(MEs, trait.of.interest, use = "p")))
  for (mod in 1:ncol(TaxaModuleMembership)) {
    oldNames = names(TaxaInfo0)
    TaxaInfo0 = data.frame(TaxaInfo0, TaxaModuleMembership[, modOrder[mod]],
                           MMPvalue[, modOrder[mod]]);
    names(TaxaInfo0) = c(oldNames, paste("MM.", modNames[modOrder[mod]], sep=""),
                         paste("p.MM.", modNames[modOrder[mod]], sep=""))
  }
  TaxaOrder = order(TaxaInfo0[4], -abs(TaxaInfo0[5]))
  TaxaInfo = TaxaInfo0[TaxaOrder, ]
  merge.name.csv = paste(toi.name,".community.TaxaInfo.roc.csv", sep = '')
  write.csv(TaxaInfo, file = merge.name.csv)
}

# The scatter plot shows each taxa that made it into the module and how each taxa
# correlated with 1) the environmental trait of interest (y-axis) and 2) how
# important it is to the module (x-axis)

# The OTUs that have high module membership tend to occur whenever the
# module is represented in the environment and are therefore often connected
# throughout the samples with other OTUs

# OTUs present in the top right corner will have the highest impact on
# significance in this module for a given environmental trait


# Notes on output:

# "moduleColor" is the module that the OTU was ultimately put into

# GS stands for Gene Significance (for us it means taxon significance) while MM
# stands for module membership.

# GS.Environmentaltrait = Pearson Correlation Coefficient for that OTU with the
# trait. GS allows incorporation of external info into the co-expression network
# by showing gene/OTU significance. The higher the absolute value of GS the more
# biologically significant the gene (or in our case taxa) to that external
# variable (e.g. CR). p.GS.Environmentaltrait = P value for the preceding
# relationship.

# MM.color = Pearson Correlation Coefficient for Module Membership--i.e. how
# well that OTU correlates with that particular color module (each OTU has a
# value for each module but only belongs to one module). If close to 0 or
# negative then the taxa is not part of that color module (since each OTU has to
# be put in a module you may get some OTUs that are close to 0, but they aren't
# important to that module). If it is close to 1 then it is highly connected to
# that color module, but will be placed with the color module that it is most
# connected to throughout the samples. p.MM.color = P value for the preceding
# relationship.

# Modules will be ordered by their significance for the external variable you
# selected (e.g. CR), with the most significant ones to the left. Each of the
# modules (with each OTU assigned to exactly one module) will be represented for
# the environmental trait you selected. You will have to rerun this for each
# environmental trait you are interested in.


#Chytridiomycota_FOtu0001 - modified to exclude FOtu0001 as this adds spurious
#weight to analysis
#uc_Microbotryomycete_FOtu0002
#Leucosporidiaceae_FOtu0003
#Sanguina_nivaloides_AOtu0001
#Sanguina_auruntia_AOtu0002
#Soletalia_BOtu0001
#Hymenobacter_BOtu0002
#Ferruginobacter_BOtu0003
#Polaromonas_BOtu0004

################################################################################
################################################################################
# 5a--Visualizing the OTU/taxa network

nOTU = ncol(data)
nSamples = nrow(data)

#Calculate topological overlap anew: this could be done more efficiently by
#saving the TOM
#Calculated during module detection, but let us do it again here.
dissTOM = 1-TOMsimilarityFromExpr(data, power = 10, networkType = "signed")

# Transform dissTOM with a power to make moderately strong connections more
# visible in the heatmap
plotTOM = dissTOM^10

# Set diagonal to NA for a nicer plot
diag(plotTOM) = NA

# Call the plot function
sizeGrWindow(9,9)
TOMplot(plotTOM, TaxaTree, moduleColors
        , main = "Network heatmap plot, all OTUs")

################################################################################
# If normal 5a heatmap generation takes too long you can restrict the number of
# OTU/taxa
# Still have to do first few steps from above (dissTOM creation)

nSelect = 200

# For reproducibility, we set the random seed
set.seed(10);
select = sample(nOTU, size = nSelect)
selectTOM = dissTOM[select, select]

# There's no simple way of restricting a clustering tree to a subset of OTU, so
# we must re-cluster.
selectTree = hclust(as.dist(selectTOM), method = "average")
selectColors = moduleColors[select]

# Open a graphical window
sizeGrWindow(9,9)

# Taking the dissimilarity to a power, say 10, makes the plot more informative
# by effectively changing the color palette; setting the diagonal to NA also
# improves the clarity of the plot
plotDiss = selectTOM^10
diag(plotDiss) = NA
TOMplot(plotDiss, selectTree, selectColors
        , main = "Network heatmap plot, selected OTU")

